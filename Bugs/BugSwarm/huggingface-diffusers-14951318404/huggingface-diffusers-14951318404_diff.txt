diff --git a/src/diffusers/pipelines/self_segmentation_stable_diffusion/self_segmentation_stable_diffusion.py b/src/diffusers/pipelines/self_segmentation_stable_diffusion/self_segmentation_stable_diffusion.py
index b11f2666..d9677c1a 100644
--- a/src/diffusers/pipelines/self_segmentation_stable_diffusion/self_segmentation_stable_diffusion.py
+++ b/src/diffusers/pipelines/self_segmentation_stable_diffusion/self_segmentation_stable_diffusion.py
@@ -57,7 +57,9 @@ EXAMPLE_DOC_STRING = """
         >>> import torch
         >>> from diffusers import StableDiffusionPipeline
 
-        >>> pipe = SelfSegmentationStableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
+        >>> pipe = SelfSegmentationStableDiffusionPipeline.from_pretrained(
+        ...     "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16
+        ... )
         >>> pipe = pipe.to("cuda")
 
         >>> prompt = "a cat with sunglasses"
diff --git a/src/diffusers/utils/dummy_torch_and_transformers_objects.py b/src/diffusers/utils/dummy_torch_and_transformers_objects.py
index 164206d7..0bcbc2cc 100644
--- a/src/diffusers/utils/dummy_torch_and_transformers_objects.py
+++ b/src/diffusers/utils/dummy_torch_and_transformers_objects.py
@@ -362,6 +362,21 @@ class PaintByExamplePipeline(metaclass=DummyObject):
         requires_backends(cls, ["torch", "transformers"])
 
 
+class SelfSegmentationStableDiffusionPipeline(metaclass=DummyObject):
+    _backends = ["torch", "transformers"]
+
+    def __init__(self, *args, **kwargs):
+        requires_backends(self, ["torch", "transformers"])
+
+    @classmethod
+    def from_config(cls, *args, **kwargs):
+        requires_backends(cls, ["torch", "transformers"])
+
+    @classmethod
+    def from_pretrained(cls, *args, **kwargs):
+        requires_backends(cls, ["torch", "transformers"])
+
+
 class SemanticStableDiffusionPipeline(metaclass=DummyObject):
     _backends = ["torch", "transformers"]
 
diff --git a/tests/pipelines/self_segmentation_stable_diffusion/test_self_segementation_stable_diffusion.py b/tests/pipelines/self_segmentation_stable_diffusion/test_self_segementation_stable_diffusion.py
index 847313c8..0fdaf1eb 100644
--- a/tests/pipelines/self_segmentation_stable_diffusion/test_self_segementation_stable_diffusion.py
+++ b/tests/pipelines/self_segmentation_stable_diffusion/test_self_segementation_stable_diffusion.py
@@ -29,9 +29,16 @@ from diffusers import (
 )
 from diffusers.utils import slow, torch_device
 from diffusers.utils.testing_utils import enable_full_determinism, require_torch_gpu, skip_mps
-
-from tests.pipelines.pipeline_params import TEXT_TO_IMAGE_BATCH_PARAMS, TEXT_TO_IMAGE_IMAGE_PARAMS, TEXT_TO_IMAGE_PARAMS
-from tests.pipelines.test_pipelines_common import PipelineKarrasSchedulerTesterMixin, PipelineLatentTesterMixin, PipelineTesterMixin
+from tests.pipelines.pipeline_params import (
+    TEXT_TO_IMAGE_BATCH_PARAMS,
+    TEXT_TO_IMAGE_IMAGE_PARAMS,
+    TEXT_TO_IMAGE_PARAMS,
+)
+from tests.pipelines.test_pipelines_common import (
+    PipelineKarrasSchedulerTesterMixin,
+    PipelineLatentTesterMixin,
+    PipelineTesterMixin,
+)
 
 
 enable_full_determinism()
@@ -135,7 +142,6 @@ class SelfSegmentationStableDiffusionPipelineFastTests(
         image_slice = image[0, -3:, -3:, -1]
         assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2
 
-
     def test_self_segmentation_stable_diffusion_negative_prompt(self):
         device = "cpu"  # ensure determinism for the device-dependent torch.Generator
         components = self.get_dummy_components()
@@ -188,7 +194,6 @@ class SelfSegmentationStableDiffusionPipelineFastTests(
         super().test_inference_batch_single_identical(batch_size=batch_size, expected_max_diff=expected_max_diff)
 
 
-
 @slow
 @require_torch_gpu
 class SelfSegmentationStableDiffusionSlowTests(unittest.TestCase):
@@ -228,13 +233,12 @@ class SelfSegmentationStableDiffusionSlowTests(unittest.TestCase):
 
         expected_image_slice = np.array([0.7193, 0.7838, 0.7939, 0.6914, 0.8129, 0.8475, 0.8973, 0.9721, 0.9805])
         expected_seg_map_slice = np.array([1, 5, 5, 1, 1, 5, 0, 4, 1])
-        expected_labels = {0: 'background', 1: 3, 2: 'background', 3: 1, 4: 1, 5: 3}
+        expected_labels = {0: "background", 1: 3, 2: "background", 3: 1, 4: 1, 5: 3}
 
         assert np.abs(expected_image_slice - image_slice).max() < 1e-2
         assert np.abs(expected_seg_map_slice - seg_map_slice).max() < 1e-2
         assert seg_labels == expected_labels
 
-
     def test_self_segmentation_stable_diffusion_with_sequential_cpu_offloading(self):
         torch.cuda.empty_cache()
         torch.cuda.reset_max_memory_allocated()
