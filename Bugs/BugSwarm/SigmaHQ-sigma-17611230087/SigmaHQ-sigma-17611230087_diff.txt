diff --git a/rules/cloud/gcp/gworkspace/gcp_gworkspace_application_removed.yml b/rules/cloud/gcp/gworkspace/gcp_gworkspace_application_removed.yml
new file mode 100644
index 000000000..bd00afe3d
--- /dev/null
+++ b/rules/cloud/gcp/gworkspace/gcp_gworkspace_application_removed.yml
@@ -0,0 +1,26 @@
+title: Google Workspace Application Removed
+id: ee2803f0-71c8-4831-b48b-a1fc57601ee4
+status: test
+description: Detects when an an application is removed from Google Workspace.
+references:
+    - https://cloud.google.com/logging/docs/audit/gsuite-audit-logging#3
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-domain-settings?hl=en#REMOVE_APPLICATION
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-domain-settings?hl=en#REMOVE_APPLICATION_FROM_WHITELIST
+author: Austin Songer
+date: 2021/08/26
+modified: 2023/10/11
+tags:
+    - attack.impact
+logsource:
+    product: gcp
+    service: google_workspace.admin
+detection:
+    selection:
+        eventService: admin.googleapis.com
+        eventName:
+            - REMOVE_APPLICATION
+            - REMOVE_APPLICATION_FROM_WHITELIST
+    condition: selection
+falsepositives:
+    - Application being removed may be performed by a System Administrator.
+level: medium
diff --git a/rules/cloud/gcp/gworkspace/gcp_gworkspace_granted_domain_api_access.yml b/rules/cloud/gcp/gworkspace/gcp_gworkspace_granted_domain_api_access.yml
new file mode 100644
index 000000000..332ea09bf
--- /dev/null
+++ b/rules/cloud/gcp/gworkspace/gcp_gworkspace_granted_domain_api_access.yml
@@ -0,0 +1,25 @@
+title: Google Workspace Granted Domain API Access
+id: 04e2a23a-9b29-4a5c-be3a-3542e3f982ba
+status: test
+description: Detects when an API access service account is granted domain authority.
+references:
+    - https://cloud.google.com/logging/docs/audit/gsuite-audit-logging#3
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-domain-settings#AUTHORIZE_API_CLIENT_ACCESS
+author: Austin Songer
+date: 2021/08/23
+modified: 2023/10/11
+tags:
+    - attack.persistence
+    - attack.t1098
+logsource:
+    product: gcp
+    service: google_workspace.admin
+detection:
+    selection:
+        eventService: admin.googleapis.com
+        eventName: AUTHORIZE_API_CLIENT_ACCESS
+    condition: selection
+falsepositives:
+    - Unknown
+
+level: medium
diff --git a/rules/cloud/gcp/gworkspace/gcp_gworkspace_mfa_disabled.yml b/rules/cloud/gcp/gworkspace/gcp_gworkspace_mfa_disabled.yml
new file mode 100644
index 000000000..14b5c94b1
--- /dev/null
+++ b/rules/cloud/gcp/gworkspace/gcp_gworkspace_mfa_disabled.yml
@@ -0,0 +1,28 @@
+title: Google Workspace MFA Disabled
+id: 780601d1-6376-4f2a-884e-b8d45599f78c
+status: test
+description: Detects when multi-factor authentication (MFA) is disabled.
+references:
+    - https://cloud.google.com/logging/docs/audit/gsuite-audit-logging#3
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-security-settings#ENFORCE_STRONG_AUTHENTICATION
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-security-settings?hl=en#ALLOW_STRONG_AUTHENTICATION
+author: Austin Songer
+date: 2021/08/26
+modified: 2023/10/11
+tags:
+    - attack.impact
+logsource:
+    product: gcp
+    service: google_workspace.admin
+detection:
+    selection_base:
+        eventService: admin.googleapis.com
+        eventName:
+            - ENFORCE_STRONG_AUTHENTICATION
+            - ALLOW_STRONG_AUTHENTICATION
+    selection_eventValue:
+        new_value: 'false'
+    condition: all of selection*
+falsepositives:
+    - MFA may be disabled and performed by a system administrator.
+level: medium
diff --git a/rules/cloud/gcp/gworkspace/gcp_gworkspace_role_modified_or_deleted.yml b/rules/cloud/gcp/gworkspace/gcp_gworkspace_role_modified_or_deleted.yml
new file mode 100644
index 000000000..dd6fee807
--- /dev/null
+++ b/rules/cloud/gcp/gworkspace/gcp_gworkspace_role_modified_or_deleted.yml
@@ -0,0 +1,27 @@
+title: Google Workspace Role Modified or Deleted
+id: 6aef64e3-60c6-4782-8db3-8448759c714e
+status: test
+description: Detects when an a role is modified or deleted in Google Workspace.
+references:
+    - https://cloud.google.com/logging/docs/audit/gsuite-audit-logging#3
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-delegated-admin-settings
+author: Austin Songer
+date: 2021/08/24
+modified: 2023/10/11
+tags:
+    - attack.impact
+logsource:
+    product: gcp
+    service: google_workspace.admin
+detection:
+    selection:
+        eventService: admin.googleapis.com
+        eventName:
+            - DELETE_ROLE
+            - RENAME_ROLE
+            - UPDATE_ROLE
+    condition: selection
+falsepositives:
+    - Unknown
+
+level: medium
diff --git a/rules/cloud/gcp/gworkspace/gcp_gworkspace_role_privilege_deleted.yml b/rules/cloud/gcp/gworkspace/gcp_gworkspace_role_privilege_deleted.yml
new file mode 100644
index 000000000..6732d34b6
--- /dev/null
+++ b/rules/cloud/gcp/gworkspace/gcp_gworkspace_role_privilege_deleted.yml
@@ -0,0 +1,24 @@
+title: Google Workspace Role Privilege Deleted
+id: bf638ef7-4d2d-44bb-a1dc-a238252e6267
+status: test
+description: Detects when an a role privilege is deleted in Google Workspace.
+references:
+    - https://cloud.google.com/logging/docs/audit/gsuite-audit-logging#3
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-delegated-admin-settings
+author: Austin Songer
+date: 2021/08/24
+modified: 2023/10/11
+tags:
+    - attack.impact
+logsource:
+    product: gcp
+    service: google_workspace.admin
+detection:
+    selection:
+        eventService: admin.googleapis.com
+        eventName: REMOVE_PRIVILEGE
+    condition: selection
+falsepositives:
+    - Unknown
+
+level: medium
diff --git a/rules/cloud/gcp/gworkspace/gcp_gworkspace_user_granted_admin_privileges.yml b/rules/cloud/gcp/gworkspace/gcp_gworkspace_user_granted_admin_privileges.yml
new file mode 100644
index 000000000..321fa59ff
--- /dev/null
+++ b/rules/cloud/gcp/gworkspace/gcp_gworkspace_user_granted_admin_privileges.yml
@@ -0,0 +1,26 @@
+title: Google Workspace User Granted Admin Privileges
+id: 2d1b83e4-17c6-4896-a37b-29140b40a788
+status: test
+description: Detects when an Google Workspace user is granted admin privileges.
+references:
+    - https://cloud.google.com/logging/docs/audit/gsuite-audit-logging#3
+    - https://developers.google.com/admin-sdk/reports/v1/appendix/activity/admin-user-settings#GRANT_ADMIN_PRIVILEGE
+author: Austin Songer
+date: 2021/08/23
+modified: 2023/10/11
+tags:
+    - attack.persistence
+    - attack.t1098
+logsource:
+    product: gcp
+    service: google_workspace.admin
+detection:
+    selection:
+        eventService: admin.googleapis.com
+        eventName:
+            - GRANT_DELEGATED_ADMIN_PRIVILEGES
+            - GRANT_ADMIN_PRIVILEGE
+    condition: selection
+falsepositives:
+    - Google Workspace admin role privileges, may be modified by system administrators.
+level: medium
diff --git a/tests/sigma-package-release.py b/tests/sigma-package-release.py
index bab05ccdf..7aebb462c 100644
--- a/tests/sigma-package-release.py
+++ b/tests/sigma-package-release.py
@@ -25,32 +25,63 @@ RULES_DICT = {
     "et": "rules-emerging-threats",
     "threat-hunting": "rules-threat-hunting",
     "th": "rules-threat-hunting",
-    "rules-threat-hunting": "rules-threat-hunting"
-    }
+    "rules-threat-hunting": "rules-threat-hunting",
+}
 RULES = [x for x in RULES_DICT.keys()]
 
+
 def init_arguments(arguments: list) -> list:
-    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
-    parser.add_argument('-o', '--outfile', help="Outputs the Sigma release package as ZIP archive", default="Sigma-standard.zip", required=True)
+    parser = argparse.ArgumentParser(
+        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
+    )
+    parser.add_argument(
+        "-o",
+        "--outfile",
+        help="Outputs the Sigma release package as ZIP archive",
+        default="Sigma-standard.zip",
+        required=True,
+    )
     arg_status = parser.add_mutually_exclusive_group(required=True)
-    arg_status.add_argument('-s', '--statuses', nargs='*', choices=STATUS, help="Select status of rules")
-    arg_status.add_argument('-ms', '--min-status', nargs='?', choices=STATUS, help="Sets the minimum status of rules to select")
+    arg_status.add_argument(
+        "-s", "--statuses", nargs="*", choices=STATUS, help="Select status of rules"
+    )
+    arg_status.add_argument(
+        "-ms",
+        "--min-status",
+        nargs="?",
+        choices=STATUS,
+        help="Sets the minimum status of rules to select",
+    )
     arg_level = parser.add_mutually_exclusive_group(required=True)
-    arg_level.add_argument('-l', '--levels', nargs='*', choices=LEVEL, help="Select level of rules")
-    arg_level.add_argument('-ml', '--min-level', nargs='?', choices=LEVEL, help="Sets the minimum level of rules to select")
-    parser.add_argument('-r', '--rule-types', choices=RULES, nargs='*', help="Select type of rules")
+    arg_level.add_argument(
+        "-l", "--levels", nargs="*", choices=LEVEL, help="Select level of rules"
+    )
+    arg_level.add_argument(
+        "-ml",
+        "--min-level",
+        nargs="?",
+        choices=LEVEL,
+        help="Sets the minimum level of rules to select",
+    )
+    parser.add_argument(
+        "-r", "--rule-types", choices=RULES, nargs="*", help="Select type of rules"
+    )
     args = parser.parse_args(arguments)
 
     if not args.outfile.endswith(".zip"):
         args.outfile = args.outfile + ".zip"
 
     if os.path.exists(args.outfile):
-        print("[E] '{}' already exists. Choose a different output file name.".format(args.outfile))
+        print(
+            "[E] '{}' already exists. Choose a different output file name.".format(
+                args.outfile
+            )
+        )
         sys.exit(1)
 
     if args.rule_types == None:
         args.rule_types = ["generic"]
-        print("[I] -r/--rule-types not defined: Using \"generic\" by default")
+        print('[I] -r/--rule-types not defined: Using "generic" by default')
 
     if args.min_level != None:
         i = LEVEL.index(args.min_level)
@@ -62,19 +93,20 @@ def init_arguments(arguments: list) -> list:
 
     return args
 
+
 def select_rules(args: dict) -> list:
     selected_rules = []
 
     def yield_next_rule_file_path(rule_path: str) -> str:
         for root, _, files in os.walk(rule_path):
             for file in files:
-                if file.endswith('.yml'):
+                if file.endswith(".yml"):
                     yield os.path.join(root, file)
 
     def get_rule_yaml(file_path: str) -> dict:
         data = []
 
-        with open(file_path, encoding='utf-8') as f:
+        with open(file_path, encoding="utf-8") as f:
             yaml_parts = yaml.safe_load_all(f)
             for part in yaml_parts:
                 data.append(part)
@@ -85,22 +117,29 @@ def select_rules(args: dict) -> list:
         for file in yield_next_rule_file_path(rule_path=rules_path):
             rule_yaml = get_rule_yaml(file_path=file)
             if len(rule_yaml) != 1:
-                print("[E] rule {} is a multi-document file and will be skipped".format(file))
+                print(
+                    "[E] rule {} is a multi-document file and will be skipped".format(
+                        file
+                    )
+                )
                 continue
 
             rule = rule_yaml[0]
-            if (rule["level"] in args.levels and
-                rule["status"] in args.statuses):
+            if rule["level"] in args.levels and rule["status"] in args.statuses:
                 selected_rules.append(file)
 
     return selected_rules
 
+
 def write_zip(outfile: str, selected_rules: list):
-    with zipfile.ZipFile(outfile, mode='a', compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zip:
+    with zipfile.ZipFile(
+        outfile, mode="a", compression=zipfile.ZIP_DEFLATED, compresslevel=9
+    ) as zip:
         for rule_path in selected_rules:
             zip.write(rule_path)
     return
 
+
 def main(arguments: list) -> int:
     args = init_arguments(arguments)
 
@@ -111,5 +150,6 @@ def main(arguments: list) -> int:
     write_zip(args.outfile, selected_rules)
     print("[I] Written all rules to output ZIP file '{}'".format(args.outfile))
 
-if __name__ == '__main__':
+
+if __name__ == "__main__":
     sys.exit(main(sys.argv[1:]))
diff --git a/tests/test_logsource.py b/tests/test_logsource.py
index cb60ca74f..2524c849b 100644
--- a/tests/test_logsource.py
+++ b/tests/test_logsource.py
@@ -15,30 +15,37 @@ import json
 
 
 class TestRules(unittest.TestCase):
-
-    path_to_rules_ = ["rules", "rules-emerging-threats", "rules-placeholder", "rules-threat-hunting", "rules-compliance"]
+    path_to_rules_ = [
+        "rules",
+        "rules-emerging-threats",
+        "rules-placeholder",
+        "rules-threat-hunting",
+        "rules-compliance",
+    ]
     path_to_rules = []
     for path_ in path_to_rules_:
-        path_to_rules.append(os.path.join(os.path.dirname(os.path.realpath(__name__)), path_))
+        path_to_rules.append(
+            os.path.join(os.path.dirname(os.path.realpath(__name__)), path_)
+        )
 
     # Helper functions
     def yield_next_rule_file_path(self, path_to_rules: list) -> str:
         for path_ in path_to_rules:
             for root, _, files in os.walk(path_):
                 for file in files:
-                    if file.endswith('.yml'):
+                    if file.endswith(".yml"):
                         yield os.path.join(root, file)
 
     def get_rule_yaml(self, file_path: str) -> dict:
         data = []
 
-        with open(file_path, encoding='utf-8') as f:
+        with open(file_path, encoding="utf-8") as f:
             yaml_parts = yaml.safe_load_all(f)
             for part in yaml_parts:
                 data.append(part)
 
         return data
-        
+
     def get_rule_part(self, file_path: str, part_name: str):
         yaml_dicts = self.get_rule_yaml(file_path)
         for yaml_part in yaml_dicts:
@@ -47,16 +54,16 @@ class TestRules(unittest.TestCase):
 
         return None
 
-    def get_detection_field(self,detection: dict):
+    def get_detection_field(self, detection: dict):
         data = []
-        
+
         def get_field_name(selection: dict):
             name = []
             for field in selection:
-                if field == '|all':
+                if field == "|all":
                     continue
                 elif "|" in field:
-                    name.append(field.split('|')[0])
+                    name.append(field.split("|")[0])
                 else:
                     name.append(field)
             return name
@@ -65,56 +72,82 @@ class TestRules(unittest.TestCase):
             if isinstance(detection[search_identifier], dict):
                 data += get_field_name(detection[search_identifier])
             if isinstance(detection[search_identifier], list):
-               for list_value in detection[search_identifier]:
+                for list_value in detection[search_identifier]:
                     if isinstance(list_value, dict):
                         data += get_field_name(list_value)
 
-        return data        
+        return data
 
-    def full_logsource(self,logsource: dict) -> dict:
+    def full_logsource(self, logsource: dict) -> dict:
         data = {}
-        
-        data["product"] = logsource["product"] if "product" in logsource.keys() else None
-        data["category"] = logsource["category"] if "category" in logsource.keys() else None
-        data["service"] = logsource["service"] if "service" in logsource.keys() else None
-        
+
+        data["product"] = (
+            logsource["product"] if "product" in logsource.keys() else None
+        )
+        data["category"] = (
+            logsource["category"] if "category" in logsource.keys() else None
+        )
+        data["service"] = (
+            logsource["service"] if "service" in logsource.keys() else None
+        )
+
         return data
 
-    def exist_logsource(self,logsource:dict) -> bool:
-        #Check New product
+    def exist_logsource(self, logsource: dict) -> bool:
+        # Check New product
         if logsource["product"]:
             if logsource["product"] in fieldname_dict.keys():
                 product = logsource["product"]
             else:
                 return False
         else:
-            product="empty"
-        
-        if logsource["category"] and logsource["category"] in fieldname_dict[product]['category'].keys():
+            product = "empty"
+
+        if (
+            logsource["category"]
+            and logsource["category"] in fieldname_dict[product]["category"].keys()
+        ):
             return True
-        elif logsource["service"] and logsource["service"] in fieldname_dict[product]['service'].keys():
+        elif (
+            logsource["service"]
+            and logsource["service"] in fieldname_dict[product]["service"].keys()
+        ):
             return True
         elif logsource["category"] == None and logsource["service"] == None:
-            return True # We known the product but there are no category or service 
-        
+            return True  # We known the product but there are no category or service
+
         return False
 
-    def get_logsource(self,logsource:dict) -> list:
+    def get_logsource(self, logsource: dict) -> list:
         data = None
-        
-        product = logsource["product"]  if logsource["product"] in fieldname_dict.keys() else "empty"
 
-        if logsource["category"] and logsource["category"] in fieldname_dict[product]['category'].keys():
-            data= fieldname_dict[product]["category"][logsource["category"]]
-        elif logsource["service"] and logsource["service"] in fieldname_dict[product]['service'].keys():
-            data= fieldname_dict[product]["service"][logsource["service"]]
+        product = (
+            logsource["product"]
+            if logsource["product"] in fieldname_dict.keys()
+            else "empty"
+        )
+
+        if (
+            logsource["category"]
+            and logsource["category"] in fieldname_dict[product]["category"].keys()
+        ):
+            data = fieldname_dict[product]["category"][logsource["category"]]
+        elif (
+            logsource["service"]
+            and logsource["service"] in fieldname_dict[product]["service"].keys()
+        ):
+            data = fieldname_dict[product]["service"][logsource["service"]]
         elif logsource["category"] == None and logsource["service"] == None:
             data = fieldname_dict[product]["empty"]
 
         return data
 
-    def not_commun(self,logsource:dict,data:list) -> bool:
-        product = logsource["product"]  if logsource["product"] in fieldname_dict.keys() else "empty"
+    def not_commun(self, logsource: dict, data: list) -> bool:
+        product = (
+            logsource["product"]
+            if logsource["product"] in fieldname_dict.keys()
+            else "empty"
+        )
 
         if fieldname_dict[product]["commun"] == data:
             return False
@@ -127,15 +160,14 @@ class TestRules(unittest.TestCase):
     def test_invalid_logsource_attributes(self):
         faulty_rules = []
         valid_logsource = [
-            'category',
-            'product',
-            'service',
-            'definition',
+            "category",
+            "product",
+            "service",
+            "definition",
         ]
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            logsource = self.get_rule_part(
-                file_path=file, part_name="logsource")
+            logsource = self.get_rule_part(file_path=file, part_name="logsource")
             if not logsource:
                 print(Fore.RED + "Rule {} has no 'logsource'.".format(file))
                 faulty_rules.append(file)
@@ -144,37 +176,54 @@ class TestRules(unittest.TestCase):
             for key in logsource:
                 if key not in valid_logsource:
                     print(
-                        Fore.RED + "Rule {} has a logsource with an invalid field ({})".format(file, key))
+                        Fore.RED
+                        + "Rule {} has a logsource with an invalid field ({})".format(
+                            file, key
+                        )
+                    )
                     valid = False
                 elif not isinstance(logsource[key], str):
                     print(
-                        Fore.RED + "Rule {} has a logsource with an invalid field type ({})".format(file, key))
+                        Fore.RED
+                        + "Rule {} has a logsource with an invalid field type ({})".format(
+                            file, key
+                        )
+                    )
                     valid = False
             if not valid:
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with non-conform 'logsource' fields. Please check: https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide#log-source")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with non-conform 'logsource' fields. Please check: https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide#log-source",
+        )
 
     def test_logsource_value(self):
         faulty_rules = []
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            logsource = self.get_rule_part(
-                file_path=file, part_name="logsource")
+            logsource = self.get_rule_part(file_path=file, part_name="logsource")
             if logsource:
                 full_logsource = self.full_logsource(logsource)
                 if not self.exist_logsource(full_logsource):
                     faulty_rules.append(file)
                     print(
-                        Fore.RED + "Rule {} has the unknown logsource product/category/service ({}/{}/{})".format(file,
-                                                                                                        full_logsource["product"],
-                                                                                                        full_logsource["category"],
-                                                                                                        full_logsource["service"]
-                                                                                                        ))
-
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                        "There are rules with non-conform 'logsource' values.")
+                        Fore.RED
+                        + "Rule {} has the unknown logsource product/category/service ({}/{}/{})".format(
+                            file,
+                            full_logsource["product"],
+                            full_logsource["category"],
+                            full_logsource["service"],
+                        )
+                    )
+
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED + "There are rules with non-conform 'logsource' values.",
+        )
 
     def test_fieldname_case(self):
         files_with_fieldname_issues = []
@@ -182,49 +231,73 @@ class TestRules(unittest.TestCase):
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             logsource = self.get_rule_part(file_path=file, part_name="logsource")
             detection = self.get_rule_part(file_path=file, part_name="detection")
-            
-            if logsource and detection :
+
+            if logsource and detection:
                 full_logsource = self.full_logsource(logsource)
                 list_valid = self.get_logsource(full_logsource)
                 fisrt_time = True
 
-                if list_valid and self.not_commun(full_logsource,list_valid):
+                if list_valid and self.not_commun(full_logsource, list_valid):
                     for field in self.get_detection_field(detection):
                         if not field in list_valid:
                             print(
-                                Fore.RED + "Rule {} has the invalid field <{}>".format(file, field))
+                                Fore.RED
+                                + "Rule {} has the invalid field <{}>".format(
+                                    file, field
+                                )
+                            )
                             if fisrt_time:
                                 files_with_fieldname_issues.append(file)
-                                fisrt_time = False # can be many error in the same rule
+                                fisrt_time = False  # can be many error in the same rule
 
-        self.assertEqual(files_with_fieldname_issues, [], Fore.RED +
-                         "There are rule files which contains unknown field or with cast error")
+        self.assertEqual(
+            files_with_fieldname_issues,
+            [],
+            Fore.RED
+            + "There are rule files which contains unknown field or with cast error",
+        )
 
-def load_fields_json(name:str):
+
+def load_fields_json(name: str):
     data = {}
 
-    file_path = os.path.abspath( os.path.dirname( __file__ ) ) +'/'+ name
-    with open(file_path, 'r') as file:
+    file_path = os.path.abspath(os.path.dirname(__file__)) + "/" + name
+    with open(file_path, "r") as file:
         json_dict = json.load(file)
-    
+
     for product in json_dict["legit"]:
         data[product] = json_dict["legit"][product]
 
     for product in json_dict["addon"]:
         for category in json_dict["addon"][product]["category"]:
-            data[product]["category"][category] += json_dict["addon"][product]["category"][category]
+            data[product]["category"][category] += json_dict["addon"][product][
+                "category"
+            ][category]
         for service in json_dict["addon"][product]["service"]:
-            data[product]["service"][service] += json_dict["addon"][product]["service"][service]
-
+            data[product]["service"][service] += json_dict["addon"][product]["service"][
+                service
+            ]
 
     # We use some extracted hash
     # Add commun field
     for product in data:
         for category in data[product]["category"]:
             if "Hashes" in data[product]["category"][category]:
-                data[product]["category"][category] += ["md5","sha1","sha256","Imphash"]
-            if "Hash" in data[product]["category"][category]: # Sysmon 15 create_stream_hash
-                data[product]["category"][category] += ["md5","sha1","sha256","Imphash"]
+                data[product]["category"][category] += [
+                    "md5",
+                    "sha1",
+                    "sha256",
+                    "Imphash",
+                ]
+            if (
+                "Hash" in data[product]["category"][category]
+            ):  # Sysmon 15 create_stream_hash
+                data[product]["category"][category] += [
+                    "md5",
+                    "sha1",
+                    "sha256",
+                    "Imphash",
+                ]
             if "commun" in data[product].keys():
                 data[product]["category"][category] += data[product]["commun"]
         for service in data[product]["service"]:
@@ -233,10 +306,11 @@ def load_fields_json(name:str):
 
     return data
 
+
 if __name__ == "__main__":
     init(autoreset=True)
     # load field name information
-    fieldname_dict = load_fields_json('logsource.json')
+    fieldname_dict = load_fields_json("logsource.json")
 
     # Run the tests
     unittest.main()
diff --git a/tests/test_rules.py b/tests/test_rules.py
index fdb574c22..1e3d1bd25 100755
--- a/tests/test_rules.py
+++ b/tests/test_rules.py
@@ -18,7 +18,6 @@ import collections
 
 
 class TestRules(unittest.TestCase):
-
     @classmethod
     def setUpClass(cls):
         print("Calling get_mitre_data()")
@@ -27,20 +26,42 @@ class TestRules(unittest.TestCase):
         print("Catched data - starting tests...")
 
     MITRE_TECHNIQUE_NAMES = [
-        "process_injection", "signed_binary_proxy_execution", "process_injection"]  # incomplete list
-    MITRE_TACTICS = ["initial_access", "execution", "persistence", "privilege_escalation", "defense_evasion", "credential_access",
-                     "discovery", "lateral_movement", "collection", "exfiltration", "command_and_control", "impact", "launch"]
+        "process_injection",
+        "signed_binary_proxy_execution",
+        "process_injection",
+    ]  # incomplete list
+    MITRE_TACTICS = [
+        "initial_access",
+        "execution",
+        "persistence",
+        "privilege_escalation",
+        "defense_evasion",
+        "credential_access",
+        "discovery",
+        "lateral_movement",
+        "collection",
+        "exfiltration",
+        "command_and_control",
+        "impact",
+        "launch",
+    ]
     # Don't use trademarks in rules - they require non-ASCII characters to be used on we don't want them in our rules
     TRADE_MARKS = {"MITRE ATT&CK", "ATT&CK"}
 
-    path_to_rules = ["rules", "rules-emerging-threats", "rules-placeholder", "rules-threat-hunting", "rules-compliance"]
+    path_to_rules = [
+        "rules",
+        "rules-emerging-threats",
+        "rules-placeholder",
+        "rules-threat-hunting",
+        "rules-compliance",
+    ]
 
     # Helper functions
     def yield_next_rule_file_path(self, path_to_rules: list) -> str:
         for path_ in path_to_rules:
             for root, _, files in os.walk(path_):
                 for file in files:
-                    if file.endswith('.yml'):
+                    if file.endswith(".yml"):
                         yield os.path.join(root, file)
 
     def get_rule_part(self, file_path: str, part_name: str):
@@ -54,56 +75,67 @@ class TestRules(unittest.TestCase):
     def get_rule_yaml(self, file_path: str) -> dict:
         data = []
 
-        with open(file_path, encoding='utf-8') as f:
+        with open(file_path, encoding="utf-8") as f:
             yaml_parts = yaml.safe_load_all(f)
             for part in yaml_parts:
                 data.append(part)
 
         return data
-    
+
     # Tests
     # def test_confirm_extension_is_yml(self):
-        # files_with_incorrect_extensions = []
+    # files_with_incorrect_extensions = []
 
-        # for file in self.yield_next_rule_file_path(self.path_to_rules):
-        # file_name_and_extension = os.path.splitext(file)
-        # if len(file_name_and_extension) == 2:
-        # extension = file_name_and_extension[1]
-        # if extension != ".yml":
-        # files_with_incorrect_extensions.append(file)
+    # for file in self.yield_next_rule_file_path(self.path_to_rules):
+    # file_name_and_extension = os.path.splitext(file)
+    # if len(file_name_and_extension) == 2:
+    # extension = file_name_and_extension[1]
+    # if extension != ".yml":
+    # files_with_incorrect_extensions.append(file)
 
-        # self.assertEqual(files_with_incorrect_extensions, [], Fore.RED +
-        # "There are rule files with extensions other than .yml")
+    # self.assertEqual(files_with_incorrect_extensions, [], Fore.RED +
+    # "There are rule files with extensions other than .yml")
 
     def test_legal_trademark_violations(self):
         # See Issue # https://github.com/SigmaHQ/sigma/issues/1028
         files_with_legal_issues = []
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            with open(file, 'r', encoding='utf-8') as fh:
+            with open(file, "r", encoding="utf-8") as fh:
                 file_data = fh.read()
                 for tm in self.TRADE_MARKS:
                     if tm in file_data:
                         files_with_legal_issues.append(file)
 
-        self.assertEqual(files_with_legal_issues, [], Fore.RED +
-                         "There are rule files which contains a trademark or reference that doesn't comply with the respective trademark requirements - please remove the trademark to avoid legal issues")
+        self.assertEqual(
+            files_with_legal_issues,
+            [],
+            Fore.RED
+            + "There are rule files which contains a trademark or reference that doesn't comply with the respective trademark requirements - please remove the trademark to avoid legal issues",
+        )
 
     def test_optional_tags(self):
         files_with_incorrect_tags = []
         tags_pattern = re.compile(
-            r"cve\.\d+\.\d+|attack\.(t\d{4}\.\d{3}|[gts]\d{4})$|attack\.[a-z_]+|car\.\d{4}-\d{2}-\d{3}|detection\.\w+")
+            r"cve\.\d+\.\d+|attack\.(t\d{4}\.\d{3}|[gts]\d{4})$|attack\.[a-z_]+|car\.\d{4}-\d{2}-\d{3}|detection\.\w+"
+        )
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             tags = self.get_rule_part(file_path=file, part_name="tags")
             if tags:
                 for tag in tags:
                     if tags_pattern.match(tag) == None:
                         print(
-                            Fore.RED + "Rule {} has the invalid tag <{}>".format(file, tag))
+                            Fore.RED
+                            + "Rule {} has the invalid tag <{}>".format(file, tag)
+                        )
                         files_with_incorrect_tags.append(file)
 
-        self.assertEqual(files_with_incorrect_tags, [], Fore.RED +
-                         "There are rules with incorrect/unknown Tags. (please inform us about new tags that are not yet supported in our tests) and check the correct tags here: https://github.com/SigmaHQ/sigma-specification/blob/main/Tags_specification.md ")
+        self.assertEqual(
+            files_with_incorrect_tags,
+            [],
+            Fore.RED
+            + "There are rules with incorrect/unknown Tags. (please inform us about new tags that are not yet supported in our tests) and check the correct tags here: https://github.com/SigmaHQ/sigma-specification/blob/main/Tags_specification.md ",
+        )
 
     def test_confirm_correct_mitre_tags(self):
         files_with_incorrect_mitre_tags = []
@@ -114,11 +146,19 @@ class TestRules(unittest.TestCase):
                 for tag in tags:
                     if tag.startswith("attack.") and tag not in self.MITRE_ALL:
                         print(
-                            Fore.RED + "Rule {} has the following incorrect MITRE tag {}".format(file, tag))
+                            Fore.RED
+                            + "Rule {} has the following incorrect MITRE tag {}".format(
+                                file, tag
+                            )
+                        )
                         files_with_incorrect_mitre_tags.append(file)
 
-        self.assertEqual(files_with_incorrect_mitre_tags, [], Fore.RED +
-                         "There are rules with incorrect/unknown MITRE Tags. (please inform us about new tags that are not yet supported in our tests) and check the correct tags here: https://attack.mitre.org/ ")
+        self.assertEqual(
+            files_with_incorrect_mitre_tags,
+            [],
+            Fore.RED
+            + "There are rules with incorrect/unknown MITRE Tags. (please inform us about new tags that are not yet supported in our tests) and check the correct tags here: https://attack.mitre.org/ ",
+        )
 
     def test_duplicate_tags(self):
         files_with_incorrect_mitre_tags = []
@@ -130,13 +170,18 @@ class TestRules(unittest.TestCase):
                 for tag in tags:
                     if tag in known_tags:
                         print(
-                            Fore.RED + "Rule {} has the duplicate tag {}".format(file, tag))
+                            Fore.RED
+                            + "Rule {} has the duplicate tag {}".format(file, tag)
+                        )
                         files_with_incorrect_mitre_tags.append(file)
                     else:
                         known_tags.append(tag)
 
-        self.assertEqual(files_with_incorrect_mitre_tags, [], Fore.RED +
-                         "There are rules with duplicate tags")
+        self.assertEqual(
+            files_with_incorrect_mitre_tags,
+            [],
+            Fore.RED + "There are rules with duplicate tags",
+        )
 
     def test_duplicate_references(self):
         files_with_duplicate_references = []
@@ -148,13 +193,20 @@ class TestRules(unittest.TestCase):
                 for reference in references:
                     if reference in known_references:
                         print(
-                            Fore.RED + "Rule {} has the duplicate reference {}".format(file, reference))
+                            Fore.RED
+                            + "Rule {} has the duplicate reference {}".format(
+                                file, reference
+                            )
+                        )
                         files_with_duplicate_references.append(file)
                     else:
                         known_references.append(reference)
 
-        self.assertEqual(files_with_duplicate_references, [], Fore.RED +
-                         "There are rules with duplicate references")
+        self.assertEqual(
+            files_with_duplicate_references,
+            [],
+            Fore.RED + "There are rules with duplicate references",
+        )
 
     def test_look_for_duplicate_filters(self):
         def check_list_or_recurse_on_dict(item, depth: int, special: bool) -> None:
@@ -162,12 +214,16 @@ class TestRules(unittest.TestCase):
                 check_if_list_contain_duplicates(item, depth, special)
             elif type(item) == dict and depth <= MAX_DEPTH:
                 for keys, sub_item in item.items():
-                    if "|base64" in keys or "|re" in keys: # Covers both "base64" and "base64offset" modifiers, and "re" modifier
+                    if (
+                        "|base64" in keys or "|re" in keys
+                    ):  # Covers both "base64" and "base64offset" modifiers, and "re" modifier
                         check_list_or_recurse_on_dict(sub_item, depth + 1, True)
                     else:
                         check_list_or_recurse_on_dict(sub_item, depth + 1, special)
 
-        def check_if_list_contain_duplicates(item: list, depth: int, special: bool) -> None:
+        def check_if_list_contain_duplicates(
+            item: list, depth: int, special: bool
+        ) -> None:
             try:
                 # We use a list comprehension to convert all the element to lowercase. Since we don't care about casing in SIGMA except for the following modifiers
                 #   - "base64offset"
@@ -176,11 +232,18 @@ class TestRules(unittest.TestCase):
                 if special:
                     item_ = item
                 else:
-                    item_= [i.lower() for i in item]
+                    item_ = [i.lower() for i in item]
                 if len(item_) != len(set(item_)):
                     # We find the duplicates and then print them to the user
-                    duplicates = [i for i, count in collections.Counter(item_).items() if count > 1]
-                    print(Fore.RED + "Rule {} has duplicate filters {}".format(file, duplicates))
+                    duplicates = [
+                        i
+                        for i, count in collections.Counter(item_).items()
+                        if count > 1
+                    ]
+                    print(
+                        Fore.RED
+                        + "Rule {} has duplicate filters {}".format(file, duplicates)
+                    )
                     files_with_duplicate_filters.append(file)
             except:
                 # unhashable types like dictionaries
@@ -192,12 +255,14 @@ class TestRules(unittest.TestCase):
         files_with_duplicate_filters = []
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             check_list_or_recurse_on_dict(detection, 1, False)
 
-        self.assertEqual(files_with_duplicate_filters, [], Fore.RED +
-                         "There are rules with duplicate filters")
+        self.assertEqual(
+            files_with_duplicate_filters,
+            [],
+            Fore.RED + "There are rules with duplicate filters",
+        )
 
     def test_field_name_with_space(self):
         def key_iterator(fields, faulty):
@@ -205,55 +270,67 @@ class TestRules(unittest.TestCase):
                 if " " in key:
                     faulty.append(key)
                     print(
-                        Fore.YELLOW + "Rule {} has a space in field name ({}).".format(file, key))
+                        Fore.YELLOW
+                        + "Rule {} has a space in field name ({}).".format(file, key)
+                    )
                 if type(value) == dict:
                     key_iterator(value, faulty)
 
         faulty_fieldnames = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             key_iterator(detection, faulty_fieldnames)
 
-        self.assertEqual(faulty_fieldnames, [], Fore.RED +
-                         "There are rules with an unsupported field name. Spaces are not allowed. (Replace space with an underscore character '_' )")
+        self.assertEqual(
+            faulty_fieldnames,
+            [],
+            Fore.RED
+            + "There are rules with an unsupported field name. Spaces are not allowed. (Replace space with an underscore character '_' )",
+        )
 
     def test_single_named_condition_with_x_of_them(self):
         faulty_detections = []
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             yaml = self.get_rule_yaml(file_path=file)
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
 
             has_them_in_condition = "them" in detection["condition"]
             has_only_one_named_condition = len(detection) == 2
             not_multipart_yaml_file = len(yaml) == 1
 
-            if has_them_in_condition and \
-                has_only_one_named_condition and \
-                    not_multipart_yaml_file:
+            if (
+                has_them_in_condition
+                and has_only_one_named_condition
+                and not_multipart_yaml_file
+            ):
                 faulty_detections.append(file)
 
-        self.assertEqual(faulty_detections, [], Fore.RED +
-                         "There are rules using '1/all of them' style conditions but only have one condition")
+        self.assertEqual(
+            faulty_detections,
+            [],
+            Fore.RED
+            + "There are rules using '1/all of them' style conditions but only have one condition",
+        )
 
     def test_all_of_them_condition(self):
         faulty_detections = []
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
 
             if "all of them" in detection["condition"]:
                 faulty_detections.append(file)
 
-        self.assertEqual(faulty_detections, [], Fore.RED +
-                         "There are rules using 'all of them'. Better use e.g. 'all of selection*' instead (and use the 'selection_' prefix as search-identifier).")
+        self.assertEqual(
+            faulty_detections,
+            [],
+            Fore.RED
+            + "There are rules using 'all of them'. Better use e.g. 'all of selection*' instead (and use the 'selection_' prefix as search-identifier).",
+        )
 
     def test_duplicate_detections(self):
         def compare_detections(detection1: dict, detection2: dict) -> bool:
-
             # If they have different log sources. They can't be the same
             # We first remove any definitions fields (if there are any) in the logsource to avoid typos
             detection1["logsource"].pop("definition", None)
@@ -295,7 +372,9 @@ class TestRules(unittest.TestCase):
 
                     # We add this check in case of keyword rules. Where no field is used. The parser returns a list instead of a dict
                     # If the 2 list are different that means they aren't the same
-                    if (type(detection2[named_condition]) == list) or (type(detection2[named_condition]) == list):
+                    if (type(detection2[named_condition]) == list) or (
+                        type(detection2[named_condition]) == list
+                    ):
                         condition_value1 = detection1[named_condition]
                         condition_value2 = detection2[named_condition]
                     else:
@@ -311,10 +390,8 @@ class TestRules(unittest.TestCase):
         files_and_their_detections = {}
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
-            logsource = self.get_rule_part(
-                file_path=file, part_name="logsource")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
+            logsource = self.get_rule_part(file_path=file, part_name="logsource")
             detection["logsource"] = {}
             detection["logsource"].update(logsource)
             yaml = self.get_rule_yaml(file_path=file)
@@ -329,46 +406,87 @@ class TestRules(unittest.TestCase):
 
             files_and_their_detections[file] = detection
 
-        self.assertEqual(faulty_detections, [], Fore.YELLOW +
-                         "There are rule files with exactly the same detection logic.")
+        self.assertEqual(
+            faulty_detections,
+            [],
+            Fore.YELLOW + "There are rule files with exactly the same detection logic.",
+        )
 
     def test_source_eventlog(self):
         faulty_detections = []
 
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             detection_str = str(detection).lower()
             if "'source': 'eventlog'" in detection_str:
                 faulty_detections.append(file)
 
-        self.assertEqual(faulty_detections, [], Fore.YELLOW +
-                         "There are detections with 'Source: Eventlog'. This does not add value to the detection.")
+        self.assertEqual(
+            faulty_detections,
+            [],
+            Fore.YELLOW
+            + "There are detections with 'Source: Eventlog'. This does not add value to the detection.",
+        )
 
     def test_event_id_instead_of_process_creation(self):
         faulty_detections = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            with open(file, encoding='utf-8') as f:
+            with open(file, encoding="utf-8") as f:
                 for line in f:
-                    if re.search(r'.*EventID: (?:1|4688)\s*$', line) and file not in faulty_detections:
-                        detection = self.get_rule_part(file_path=file, part_name="detection")
+                    if (
+                        re.search(r".*EventID: (?:1|4688)\s*$", line)
+                        and file not in faulty_detections
+                    ):
+                        detection = self.get_rule_part(
+                            file_path=file, part_name="detection"
+                        )
                         if detection:
                             for search_identifier in detection:
                                 if isinstance(detection[search_identifier], dict):
                                     for field in detection[search_identifier]:
                                         if "Provider_Name" in field:
-                                            if isinstance(detection[search_identifier]["Provider_Name"], list):
-                                                for value in detection[search_identifier]["Provider_Name"]:
-                                                    if "Microsoft-Windows-Security-Auditing" in value or "Microsoft-Windows-Sysmon" in value:
-                                                        if file not in faulty_detections:
-                                                            faulty_detections.append(file)
+                                            if isinstance(
+                                                detection[search_identifier][
+                                                    "Provider_Name"
+                                                ],
+                                                list,
+                                            ):
+                                                for value in detection[
+                                                    search_identifier
+                                                ]["Provider_Name"]:
+                                                    if (
+                                                        "Microsoft-Windows-Security-Auditing"
+                                                        in value
+                                                        or "Microsoft-Windows-Sysmon"
+                                                        in value
+                                                    ):
+                                                        if (
+                                                            file
+                                                            not in faulty_detections
+                                                        ):
+                                                            faulty_detections.append(
+                                                                file
+                                                            )
                                             else:
-                                                if "Microsoft-Windows-Security-Auditing" in detection[search_identifier]["Provider_Name"] or "Microsoft-Windows-Sysmon" in detection[search_identifier]["Provider_Name"]:
+                                                if (
+                                                    "Microsoft-Windows-Security-Auditing"
+                                                    in detection[search_identifier][
+                                                        "Provider_Name"
+                                                    ]
+                                                    or "Microsoft-Windows-Sysmon"
+                                                    in detection[search_identifier][
+                                                        "Provider_Name"
+                                                    ]
+                                                ):
                                                     if file not in faulty_detections:
-                                                            faulty_detections.append(file)
+                                                        faulty_detections.append(file)
 
-        self.assertEqual(faulty_detections, [], Fore.YELLOW +
-                         "There are rules still using Sysmon 1 or Event ID 4688. Please migrate to the process_creation category.")
+        self.assertEqual(
+            faulty_detections,
+            [],
+            Fore.YELLOW
+            + "There are rules still using Sysmon 1 or Event ID 4688. Please migrate to the process_creation category.",
+        )
 
     def test_missing_id(self):
         faulty_rules = []
@@ -380,44 +498,56 @@ class TestRules(unittest.TestCase):
                 faulty_rules.append(file)
             elif len(id) != 36:
                 print(
-                    Fore.YELLOW + "Rule {} has a malformed 'id' (not 36 chars).".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a malformed 'id' (not 36 chars).".format(file)
+                )
                 faulty_rules.append(file)
             elif id.lower() in dict_id.keys():
                 print(
-                    Fore.YELLOW + "Rule {} has the same 'id' as {}. Ids have to be unique.".format(file, dict_id[id]))
+                    Fore.YELLOW
+                    + "Rule {} has the same 'id' as {}. Ids have to be unique.".format(
+                        file, dict_id[id]
+                    )
+                )
                 faulty_rules.append(file)
             else:
                 dict_id[id.lower()] = file
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with missing or malformed 'id' fields. Generate an id (e.g. here: https://www.uuidgenerator.net/version4) and add it to the reported rule(s).")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with missing or malformed 'id' fields. Generate an id (e.g. here: https://www.uuidgenerator.net/version4) and add it to the reported rule(s).",
+        )
 
     def test_optional_related(self):
         faulty_rules = []
-        valid_type = [
-            "derived",
-            "obsoletes",
-            "merged",
-            "renamed",
-            "similar"
-        ]
+        valid_type = ["derived", "obsoletes", "merged", "renamed", "similar"]
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            related_lst = self.get_rule_part(
-                file_path=file, part_name="related")
+            related_lst = self.get_rule_part(file_path=file, part_name="related")
             if related_lst:
                 # it exists but isn't a list
                 if not isinstance(related_lst, list):
                     print(
-                        Fore.YELLOW + "Rule {} has a 'related' field that isn't a list.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a 'related' field that isn't a list.".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
                 else:
                     type_ok = True
                     for ref in related_lst:
                         try:
-                            id_str = ref['id']
-                            type_str = ref['type']
+                            id_str = ref["id"]
+                            type_str = ref["type"]
                         except KeyError:
-                            print(Fore.YELLOW + "Rule {} has an invalid form of 'related/type' value.".format(file))
+                            print(
+                                Fore.YELLOW
+                                + "Rule {} has an invalid form of 'related/type' value.".format(
+                                    file
+                                )
+                            )
                             faulty_rules.append(file)
                             continue
                         if not type_str in valid_type:
@@ -425,45 +555,60 @@ class TestRules(unittest.TestCase):
                     # Only add one time if many bad type in the same file
                     if type_ok == False:
                         print(
-                            Fore.YELLOW + "Rule {} has a 'related/type' invalid value.".format(file))
+                            Fore.YELLOW
+                            + "Rule {} has a 'related/type' invalid value.".format(file)
+                        )
                         faulty_rules.append(file)
             else:
                 typo_list = []
                 # Add more typos
-                typo_list.append(self.get_rule_part(file_path=file, part_name="realted"))
-                typo_list.append(self.get_rule_part(file_path=file, part_name="relatde"))
+                typo_list.append(
+                    self.get_rule_part(file_path=file, part_name="realted")
+                )
+                typo_list.append(
+                    self.get_rule_part(file_path=file, part_name="relatde")
+                )
                 typo_list.append(self.get_rule_part(file_path=file, part_name="relted"))
                 typo_list.append(self.get_rule_part(file_path=file, part_name="rlated"))
 
                 for i in typo_list:
                     if i != None:
                         print(
-                            Fore.YELLOW + "Rule {} has a typo in it's 'related' field.".format(file))
+                            Fore.YELLOW
+                            + "Rule {} has a typo in it's 'related' field.".format(file)
+                        )
                         faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed optional 'related' fields. (check https://github.com/SigmaHQ/sigma-specification)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed optional 'related' fields. (check https://github.com/SigmaHQ/sigma-specification)",
+        )
 
     def test_sysmon_rule_without_eventid(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            logsource = self.get_rule_part(
-                file_path=file, part_name="logsource")
+            logsource = self.get_rule_part(file_path=file, part_name="logsource")
             if logsource:
-                service = logsource.get('service', '')
-                if service.lower() == 'sysmon':
-                    with open(file, encoding='utf-8') as f:
+                service = logsource.get("service", "")
+                if service.lower() == "sysmon":
+                    with open(file, encoding="utf-8") as f:
                         found = False
                         for line in f:
                             # might be on a single line or in multiple lines
-                            if re.search(r'.*EventID:.*$', line):
+                            if re.search(r".*EventID:.*$", line):
                                 found = True
                                 break
                         if not found:
                             faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules using sysmon events but with no EventID specified")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules using sysmon events but with no EventID specified",
+        )
 
     def test_missing_date(self):
         faulty_rules = []
@@ -474,89 +619,138 @@ class TestRules(unittest.TestCase):
                 faulty_rules.append(file)
             elif not isinstance(datefield, str):
                 print(
-                    Fore.YELLOW + "Rule {} has a malformed 'date' (should be YYYY/MM/DD).".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a malformed 'date' (should be YYYY/MM/DD).".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
             elif len(datefield) != 10:
                 print(
-                    Fore.YELLOW + "Rule {} has a malformed 'date' (not 10 chars, should be YYYY/MM/DD).".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a malformed 'date' (not 10 chars, should be YYYY/MM/DD).".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
-            elif datefield[4] != '/' or datefield[7] != '/':
+            elif datefield[4] != "/" or datefield[7] != "/":
                 print(
-                    Fore.YELLOW + "Rule {} has a malformed 'date' (should be YYYY/MM/DD).".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a malformed 'date' (should be YYYY/MM/DD).".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with missing or malformed 'date' fields. (create one, e.g. date: 2019/01/14)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with missing or malformed 'date' fields. (create one, e.g. date: 2019/01/14)",
+        )
 
     def test_missing_description(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             descriptionfield = self.get_rule_part(
-                file_path=file, part_name="description")
+                file_path=file, part_name="description"
+            )
             if not descriptionfield:
                 print(Fore.YELLOW + "Rule {} has no field 'description'.".format(file))
                 faulty_rules.append(file)
             elif not isinstance(descriptionfield, str):
                 print(
-                    Fore.YELLOW + "Rule {} has a 'description' field that isn't a string.".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a 'description' field that isn't a string.".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
             elif len(descriptionfield) < 16:
                 print(
-                    Fore.YELLOW + "Rule {} has a really short description. Please elaborate.".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a really short description. Please elaborate.".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with missing or malformed 'description' field. (create one, e.g. description: Detects the suspicious behaviour of process XY doing YZ)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with missing or malformed 'description' field. (create one, e.g. description: Detects the suspicious behaviour of process XY doing YZ)",
+        )
 
     def test_optional_date_modified(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            modifiedfield = self.get_rule_part(
-                file_path=file, part_name="modified")
+            modifiedfield = self.get_rule_part(file_path=file, part_name="modified")
             if modifiedfield:
                 if not isinstance(modifiedfield, str):
                     print(
-                        Fore.YELLOW + "Rule {} has a malformed 'modified' (should be YYYY/MM/DD).".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a malformed 'modified' (should be YYYY/MM/DD).".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
                 elif len(modifiedfield) != 10:
                     print(
-                        Fore.YELLOW + "Rule {} has a malformed 'modified' (not 10 chars, should be YYYY/MM/DD).".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a malformed 'modified' (not 10 chars, should be YYYY/MM/DD).".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
-                elif modifiedfield[4] != '/' or modifiedfield[7] != '/':
+                elif modifiedfield[4] != "/" or modifiedfield[7] != "/":
                     print(
-                        Fore.YELLOW + "Rule {} has a malformed 'modified' (should be YYYY/MM/DD).".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a malformed 'modified' (should be YYYY/MM/DD).".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed 'modified' fields. (create one, e.g. date: 2019/01/14)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed 'modified' fields. (create one, e.g. date: 2019/01/14)",
+        )
 
     def test_optional_status(self):
         faulty_rules = []
-        valid_status = [
-            "stable",
-            "test",
-            "experimental",
-            "deprecated",
-            "unsupported"
-        ]
+        valid_status = ["stable", "test", "experimental", "deprecated", "unsupported"]
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             status_str = self.get_rule_part(file_path=file, part_name="status")
             if status_str:
                 if not status_str in valid_status:
                     print(
-                        Fore.YELLOW + "Rule {} has a invalid 'status' (check wiki).".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a invalid 'status' (check wiki).".format(file)
+                    )
                     faulty_rules.append(file)
                 elif status_str == "unsupported":
                     print(
-                        Fore.YELLOW + "Rule {} has the unsupported 'status', can not be in rules directory".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has the unsupported 'status', can not be in rules directory".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
             else:
                 print(
-                        Fore.YELLOW + "Rule {} is missing the 'status' field".format(file))
+                    Fore.YELLOW + "Rule {} is missing the 'status' field".format(file)
+                )
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed or missing 'status' fields. (check https://github.com/SigmaHQ/sigma-specification)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed or missing 'status' fields. (check https://github.com/SigmaHQ/sigma-specification)",
+        )
 
     def test_level(self):
         faulty_rules = []
@@ -574,11 +768,17 @@ class TestRules(unittest.TestCase):
                 faulty_rules.append(file)
             elif not level_str in valid_level:
                 print(
-                    Fore.YELLOW + "Rule {} has a invalid 'level' (check wiki).".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a invalid 'level' (check wiki).".format(file)
+                )
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with missing or malformed 'level' fields. (check https://github.com/SigmaHQ/sigma-specification)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with missing or malformed 'level' fields. (check https://github.com/SigmaHQ/sigma-specification)",
+        )
 
     def test_optional_fields(self):
         faulty_rules = []
@@ -588,70 +788,103 @@ class TestRules(unittest.TestCase):
                 # it exists but isn't a list
                 if not isinstance(fields_str, list):
                     print(
-                        Fore.YELLOW + "Rule {} has a 'fields' field that isn't a list.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a 'fields' field that isn't a list.".format(file)
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed optional 'fields' fields. (has to be a list of values even if it contains only a single value)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed optional 'fields' fields. (has to be a list of values even if it contains only a single value)",
+        )
 
     def test_optional_falsepositives_listtype(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             falsepositives_str = self.get_rule_part(
-                file_path=file, part_name="falsepositives")
+                file_path=file, part_name="falsepositives"
+            )
             if falsepositives_str:
                 # it exists but isn't a list
                 if not isinstance(falsepositives_str, list):
                     print(
-                        Fore.YELLOW + "Rule {} has a 'falsepositives' field that isn't a list.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a 'falsepositives' field that isn't a list.".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed optional 'falsepositives' fields. (has to be a list of values even if it contains only a single value)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed optional 'falsepositives' fields. (has to be a list of values even if it contains only a single value)",
+        )
 
     def test_optional_falsepositives_capital(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            fps = self.get_rule_part(
-                file_path=file, part_name="falsepositives")
+            fps = self.get_rule_part(file_path=file, part_name="falsepositives")
             if fps:
                 for fp in fps:
                     # first letter should be capital
                     try:
                         if fp[0].upper() != fp[0]:
                             print(
-                                Fore.YELLOW + "Rule {} defines a falsepositive that does not start with a capital letter: '{}'.".format(file, fp))
+                                Fore.YELLOW
+                                + "Rule {} defines a falsepositive that does not start with a capital letter: '{}'.".format(
+                                    file, fp
+                                )
+                            )
                             faulty_rules.append(file)
                     except TypeError as err:
                         print("TypeError Exception for rule {}".format(file))
                         print("Error: {}".format(err))
                         print("Maybe you created an empty falsepositive item?")
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with false positives that don't start with a capital letter (e.g. 'unknown' should be 'Unknown')")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with false positives that don't start with a capital letter (e.g. 'unknown' should be 'Unknown')",
+        )
 
     def test_optional_falsepositives_blocked_content(self):
         faulty_rules = []
         banned_words = ["none", "pentest", "penetration test"]
         common_typos = ["unkown", "ligitimate", "legitim ", "legitimeate"]
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            fps = self.get_rule_part(
-                file_path=file, part_name="falsepositives")
+            fps = self.get_rule_part(file_path=file, part_name="falsepositives")
             if fps:
                 for fp in fps:
                     for typo in common_typos:
                         if fp == "Unknow" or typo in fp.lower():
                             print(
-                                Fore.YELLOW + "Rule {} defines a falsepositive with a common typo: '{}'.".format(file, typo))
+                                Fore.YELLOW
+                                + "Rule {} defines a falsepositive with a common typo: '{}'.".format(
+                                    file, typo
+                                )
+                            )
                             faulty_rules.append(file)
                     for banned_word in banned_words:
                         if banned_word in fp.lower():
                             print(
-                                Fore.YELLOW + "Rule {} defines a falsepositive with an invalid reason: '{}'.".format(file, banned_word))
+                                Fore.YELLOW
+                                + "Rule {} defines a falsepositive with an invalid reason: '{}'.".format(
+                                    file, banned_word
+                                )
+                            )
                             faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with invalid false positive definitions (e.g. Pentest, None or common typos)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with invalid false positive definitions (e.g. Pentest, None or common typos)",
+        )
 
     # Upgrade Detection Rule License  1.1
     def test_optional_author(self):
@@ -662,25 +895,40 @@ class TestRules(unittest.TestCase):
                 # it exists but isn't a string
                 if not isinstance(author_str, str):
                     print(
-                        Fore.YELLOW + "Rule {} has a 'author' field that isn't a string.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a 'author' field that isn't a string.".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed 'author' fields. (has to be a string even if it contains many author)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed 'author' fields. (has to be a string even if it contains many author)",
+        )
 
     def test_optional_license(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            license_str = self.get_rule_part(
-                file_path=file, part_name="license")
+            license_str = self.get_rule_part(file_path=file, part_name="license")
             if license_str:
                 if not isinstance(license_str, str):
                     print(
-                        Fore.YELLOW + "Rule {} has a malformed 'license' (has to be a string).".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a malformed 'license' (has to be a string).".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed 'license' fields. (has to be a string )")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed 'license' fields. (has to be a string )",
+        )
 
     def test_optional_tlp(self):
         faulty_rules = []
@@ -696,15 +944,23 @@ class TestRules(unittest.TestCase):
                 # it exists but isn't a string
                 if not isinstance(tlp_str, str):
                     print(
-                        Fore.YELLOW + "Rule {} has a 'tlp' field that isn't a string.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a 'tlp' field that isn't a string.".format(file)
+                    )
                     faulty_rules.append(file)
                 elif not tlp_str.upper() in valid_tlp:
                     print(
-                        Fore.YELLOW + "Rule {} has a 'tlp' field with not valid value.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a 'tlp' field with not valid value.".format(file)
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed optional 'tlp' fields. (https://www.cisa.gov/tlp)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed optional 'tlp' fields. (https://www.cisa.gov/tlp)",
+        )
 
     def test_optional_target(self):
         faulty_rules = []
@@ -714,17 +970,22 @@ class TestRules(unittest.TestCase):
                 # it exists but isn't a list
                 if not isinstance(target, list):
                     print(
-                        Fore.YELLOW + "Rule {} has a 'target' field that isn't a list.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a 'target' field that isn't a list.".format(file)
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed 'target' fields. (has to be a list of values even if it contains only a single value)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed 'target' fields. (has to be a list of values even if it contains only a single value)",
+        )
 
     def test_references(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            references = self.get_rule_part(
-                file_path=file, part_name="references")
+            references = self.get_rule_part(file_path=file, part_name="references")
             # Reference field doesn't exist
             # if not references:
             # print(Fore.YELLOW + "Rule {} has no field 'references'.".format(file))
@@ -733,67 +994,98 @@ class TestRules(unittest.TestCase):
                 # it exists but isn't a list
                 if not isinstance(references, list):
                     print(
-                        Fore.YELLOW + "Rule {} has a references field that isn't a list.".format(file))
+                        Fore.YELLOW
+                        + "Rule {} has a references field that isn't a list.".format(
+                            file
+                        )
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed 'references' fields. (has to be a list of values even if it contains only a single value)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed 'references' fields. (has to be a list of values even if it contains only a single value)",
+        )
 
     def test_references_in_description(self):
         # This test checks for the presence of a links and special keywords in the "description" field while there is no "references" field.
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            references = self.get_rule_part(
-                file_path=file, part_name="references")
+            references = self.get_rule_part(file_path=file, part_name="references")
             # Reference field doesn't exist
             if not references:
                 descriptionfield = self.get_rule_part(
-                    file_path=file, part_name="description")
+                    file_path=file, part_name="description"
+                )
                 if descriptionfield:
-                    for i in ["http://", "https://", "internal research"]: # Extends the list with other common references starters
+                    for i in [
+                        "http://",
+                        "https://",
+                        "internal research",
+                    ]:  # Extends the list with other common references starters
                         if i in descriptionfield.lower():
-                            print(Fore.RED + "Rule {} has a field that contains references to external links but no references set. Add a 'references' key and add URLs as list items.".format(file))
+                            print(
+                                Fore.RED
+                                + "Rule {} has a field that contains references to external links but no references set. Add a 'references' key and add URLs as list items.".format(
+                                    file
+                                )
+                            )
                             faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed 'description' fields. (links and external references have to be in a seperate field named 'references'. see specification https://github.com/SigmaHQ/sigma-specification)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed 'description' fields. (links and external references have to be in a seperate field named 'references'. see specification https://github.com/SigmaHQ/sigma-specification)",
+        )
 
     def test_references_plural(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            reference = self.get_rule_part(
-                file_path=file, part_name="reference")
+            reference = self.get_rule_part(file_path=file, part_name="reference")
             if reference:
                 # it exists but in singular form
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with malformed 'references' fields. (has to be 'references' in plural form, not singular)")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with malformed 'references' fields. (has to be 'references' in plural form, not singular)",
+        )
 
     def test_file_names(self):
         faulty_rules = []
         name_lst = []
-        filename_pattern = re.compile(r'[a-z0-9_]{10,90}\.yml')
+        filename_pattern = re.compile(r"[a-z0-9_]{10,90}\.yml")
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             filename = os.path.basename(file)
             if filename in name_lst:
                 print(Fore.YELLOW + "Rule {} is a duplicate file name.".format(file))
                 faulty_rules.append(file)
             elif filename[-4:] != ".yml":
-                print(Fore.YELLOW +
-                      "Rule {} has a invalid extension (.yml).".format(file))
+                print(
+                    Fore.YELLOW + "Rule {} has a invalid extension (.yml).".format(file)
+                )
                 faulty_rules.append(file)
             elif len(filename) > 90:
-                print(Fore.YELLOW +
-                      "Rule {} has a file name too long >90.".format(file))
+                print(
+                    Fore.YELLOW + "Rule {} has a file name too long >90.".format(file)
+                )
                 faulty_rules.append(file)
             elif len(filename) < 14:
-                print(Fore.YELLOW +
-                      "Rule {} has a file name too short <10.".format(file))
+                print(
+                    Fore.YELLOW + "Rule {} has a file name too short <10.".format(file)
+                )
                 faulty_rules.append(file)
-            elif filename_pattern.match(filename) == None or not '_' in filename:
+            elif filename_pattern.match(filename) == None or not "_" in filename:
                 print(
-                    Fore.YELLOW + "Rule {} has a file name that doesn't match our standard.".format(file))
+                    Fore.YELLOW
+                    + "Rule {} has a file name that doesn't match our standard.".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
             else:
                 # This test make sure that every rules has a filename that corresponds to
@@ -804,7 +1096,7 @@ class TestRules(unittest.TestCase):
                     pattern_prefix = ""
                     os_infix = ""
                     os_bool = False
-                    for key,value in logsource.items():
+                    for key, value in logsource.items():
                         if key == "definition":
                             pass
                         else:
@@ -823,8 +1115,6 @@ class TestRules(unittest.TestCase):
                                     pattern_prefix = "azure_"
                                 elif value == "gcp":
                                     pattern_prefix = "gcp_"
-                                elif value == "gworkspace":
-                                    pattern_prefix = "gworkspace_"
                                 elif value == "m365":
                                     pattern_prefix = "microsoft365_"
                                 elif value == "okta":
@@ -929,7 +1219,10 @@ class TestRules(unittest.TestCase):
                                     pattern_prefix = "win_bitlocker_"
                                 elif value == "capi2":
                                     pattern_prefix = "win_capi2_"
-                                elif value == "certificateservicesclient-lifecycle-system":
+                                elif (
+                                    value
+                                    == "certificateservicesclient-lifecycle-system"
+                                ):
                                     pattern_prefix = "win_certificateservicesclient_lifecycle_system_"
                                 elif value == "pim":
                                     pattern_prefix = "azure_pim_"
@@ -940,36 +1233,44 @@ class TestRules(unittest.TestCase):
                     if pattern_prefix != "":
                         if not filename.startswith(pattern_prefix):
                             print(
-                                Fore.YELLOW + "Rule {} has a file name that doesn't match our standard naming convention.".format(file))
+                                Fore.YELLOW
+                                + "Rule {} has a file name that doesn't match our standard naming convention.".format(
+                                    file
+                                )
+                            )
                             faulty_rules.append(file)
             name_lst.append(filename)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         r'There are rules with malformed file names (too short, too long, uppercase letters, a minus sign etc.). Please see the file names used in our repository and adjust your file names accordingly. The pattern for a valid file name is \'[a-z0-9_]{10,90}\.yml\' and it has to contain at least an underline character. It also has to follow the following naming convention https://github.com/SigmaHQ/sigma-specification/blob/main/sigmahq/Sigmahq_filename_rule.md')
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + r"There are rules with malformed file names (too short, too long, uppercase letters, a minus sign etc.). Please see the file names used in our repository and adjust your file names accordingly. The pattern for a valid file name is \'[a-z0-9_]{10,90}\.yml\' and it has to contain at least an underline character. It also has to follow the following naming convention https://github.com/SigmaHQ/sigma-specification/blob/main/sigmahq/Sigmahq_filename_rule.md",
+        )
 
     def test_title(self):
         faulty_rules = []
         allowed_lowercase_words = [
-            'the',
-            'for',
-            'in',
-            'with',
-            'via',
-            'on',
-            'to',
-            'without',
-            'of',
-            'through',
-            'from',
-            'by',
-            'as',
-            'a',
-            'or',
-            'at',
-            'and',
-            'an',
-            'over',
-            'new',
+            "the",
+            "for",
+            "in",
+            "with",
+            "via",
+            "on",
+            "to",
+            "without",
+            "of",
+            "through",
+            "from",
+            "by",
+            "as",
+            "a",
+            "or",
+            "at",
+            "and",
+            "an",
+            "over",
+            "new",
         ]
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             title = self.get_rule_part(file_path=file, part_name="title")
@@ -978,25 +1279,47 @@ class TestRules(unittest.TestCase):
                 faulty_rules.append(file)
                 continue
             elif len(title) > 100:
-                print(Fore.YELLOW + "Rule {} has a title field with too many characters (>100)".format(file))
+                print(
+                    Fore.YELLOW
+                    + "Rule {} has a title field with too many characters (>100)".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
             if title.startswith("Detects "):
-                print(Fore.RED + "Rule {} has a title that starts with 'Detects'".format(file))
+                print(
+                    Fore.RED
+                    + "Rule {} has a title that starts with 'Detects'".format(file)
+                )
                 faulty_rules.append(file)
             if title.endswith("."):
                 print(Fore.RED + "Rule {} has a title that ends with '.'".format(file))
                 faulty_rules.append(file)
             wrong_casing = []
             for word in title.split(" "):
-                if word.islower() and not word.lower() in allowed_lowercase_words and not "." in word and not "/" in word and not word[0].isdigit():
+                if (
+                    word.islower()
+                    and not word.lower() in allowed_lowercase_words
+                    and not "." in word
+                    and not "/" in word
+                    and not word[0].isdigit()
+                ):
                     wrong_casing.append(word)
             if len(wrong_casing) > 0:
-                print(Fore.RED + "Rule {} has a title that has not title capitalization. Words: '{}'".format(
-                    file, ", ".join(wrong_casing)))
+                print(
+                    Fore.RED
+                    + "Rule {} has a title that has not title capitalization. Words: '{}'".format(
+                        file, ", ".join(wrong_casing)
+                    )
+                )
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with non-conform 'title' fields. Please check: https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide#title")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with non-conform 'title' fields. Please check: https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide#title",
+        )
 
     def test_title_in_first_line(self):
         faulty_rules = []
@@ -1012,30 +1335,47 @@ class TestRules(unittest.TestCase):
             # (also assumes dict keeps the order from the input file)
             if list(yaml[0].keys())[0] != "title":
                 print(
-                    Fore.RED + "Rule {} does not have its 'title' attribute in the first line".format(file))
+                    Fore.RED
+                    + "Rule {} does not have its 'title' attribute in the first line".format(
+                        file
+                    )
+                )
                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules without the 'title' attribute in their first line.")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules without the 'title' attribute in their first line.",
+        )
 
     def test_duplicate_titles(self):
         # This test ensure that every rule has a unique title
         faulty_rules = []
         titles_dict = {}
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            title = self.get_rule_part(file_path=file, part_name="title").lower().rstrip()
+            title = (
+                self.get_rule_part(file_path=file, part_name="title").lower().rstrip()
+            )
             duplicate = False
             for rule, title_ in titles_dict.items():
                 if title == title_:
-                    print(Fore.RED + "Rule {} has an already used title in {}.".format(file, rule))
+                    print(
+                        Fore.RED
+                        + "Rule {} has an already used title in {}.".format(file, rule)
+                    )
                     duplicate = True
                     faulty_rules.append(file)
                     continue
             if not duplicate:
                 titles_dict[file] = title
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules that share the same 'title'. Please check: https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide#title")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules that share the same 'title'. Please check: https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide#title",
+        )
 
     # def test_invalid_logsource_attributes(self):
     #     faulty_rules = []
@@ -1069,12 +1409,14 @@ class TestRules(unittest.TestCase):
     #                      "There are rules with non-conform 'logsource' fields. Please check: https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide#log-source")
 
     def test_selection_list_one_value(self):
-
         def treat_list(file, values, valid_, selection_name):
             # rule with only list of Keywords term
             if len(values) == 1 and not isinstance(values[0], str):
                 print(
-                    Fore.RED + "Rule {} has the selection ({}) with a list of only 1 element in detection".format(file, key)
+                    Fore.RED
+                    + "Rule {} has the selection ({}) with a list of only 1 element in detection".format(
+                        file, key
+                    )
                 )
                 valid_ = False
             elif isinstance(values[0], dict):
@@ -1088,8 +1430,11 @@ class TestRules(unittest.TestCase):
                         if isinstance(dict_[key_], list):
                             if len(dict_[key_]) == 1:
                                 print(
-                                    Fore.RED + "Rule {} has the selection ({}/{}) with a list of only 1 value in detection".format(file, selection_name, key_)
+                                    Fore.RED
+                                    + "Rule {} has the selection ({}/{}) with a list of only 1 value in detection".format(
+                                        file, selection_name, key_
                                     )
+                                )
                                 valid_ = False
             else:
                 dict_ = values
@@ -1097,17 +1442,18 @@ class TestRules(unittest.TestCase):
                     if isinstance(dict_[key_], list):
                         if len(dict_[key_]) == 1:
                             print(
-                                Fore.RED + "Rule {} has the selection ({}/{}) with a list of only 1 value in detection".format(file, selection_name, key_)
+                                Fore.RED
+                                + "Rule {} has the selection ({}/{}) with a list of only 1 value in detection".format(
+                                    file, selection_name, key_
                                 )
+                            )
                             valid_ = False
             return valid_
 
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             if detection:
-
                 valid = True
                 for key in detection:
                     values = detection[key]
@@ -1120,38 +1466,57 @@ class TestRules(unittest.TestCase):
                     if not valid:
                         faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                            "There are rules using list with only 1 element")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED + "There are rules using list with only 1 element",
+        )
 
     def test_selection_start_or_and(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             if detection:
-
                 # This test is a best effort to avoid breaking SIGMAC parser. You could do more testing and try to fix this once and for all by modifiying the token regular expressions https://github.com/SigmaHQ/sigma/blob/b9ae5303f12cda8eb6b5b90a32fd7f11ad65645d/tools/sigma/parser/condition.py#L107-L127
                 for key in detection:
                     if key[:3].lower() == "sel":
-                       continue
+                        continue
                     elif key[:2].lower() == "or":
-                        print( Fore.RED + "Rule {} has a selection '{}' that starts with the string 'or'".format(file, key))
+                        print(
+                            Fore.RED
+                            + "Rule {} has a selection '{}' that starts with the string 'or'".format(
+                                file, key
+                            )
+                        )
                         faulty_rules.append(file)
                     elif key[:3].lower() == "and":
-                        print( Fore.RED + "Rule {} has a selection '{}' that starts with the string 'and'".format(file, key))
+                        print(
+                            Fore.RED
+                            + "Rule {} has a selection '{}' that starts with the string 'and'".format(
+                                file, key
+                            )
+                        )
                         faulty_rules.append(file)
                     elif key[:3].lower() == "not":
-                        print( Fore.RED + "Rule {} has a selection '{}' that starts with the string 'not'".format(file, key))
+                        print(
+                            Fore.RED
+                            + "Rule {} has a selection '{}' that starts with the string 'not'".format(
+                                file, key
+                            )
+                        )
                         faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                            "There are rules with bad selection names. Can't start a selection name with an 'or*' or an 'and*' or a 'not*' ")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with bad selection names. Can't start a selection name with an 'or*' or an 'and*' or a 'not*' ",
+        )
 
     def test_unused_selection(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             condition = detection["condition"]
             wildcard_selections = re.compile(r"\sof\s([\w\*]+)(?:$|\s|\))")
 
@@ -1166,7 +1531,16 @@ class TestRules(unittest.TestCase):
                     continue
 
                 # remove special keywords
-                condition_list = condition.replace("not ", '').replace("1 of ", '').replace("all of ", '').replace(' or ', ' ').replace(' and ', ' ').replace('(', '').replace(')', '').split(" ")
+                condition_list = (
+                    condition.replace("not ", "")
+                    .replace("1 of ", "")
+                    .replace("all of ", "")
+                    .replace(" or ", " ")
+                    .replace(" and ", " ")
+                    .replace("(", "")
+                    .replace(")", "")
+                    .split(" ")
+                )
                 if selection in condition_list:
                     continue
 
@@ -1174,17 +1548,23 @@ class TestRules(unittest.TestCase):
                 found = False
                 for wildcard_selection in wildcard_selections.findall(condition):
                     # wildcard matches selection
-                    if re.search(wildcard_selection.replace(r"*", r".*"), selection) is not None:
+                    if (
+                        re.search(wildcard_selection.replace(r"*", r".*"), selection)
+                        is not None
+                    ):
                         found = True
                         break
                 # selection was not found in condition
                 if not found:
                     print(
-                        Fore.RED + "Rule {} has an unused selection '{}'".format(file, selection))
+                        Fore.RED
+                        + "Rule {} has an unused selection '{}'".format(file, selection)
+                    )
                     faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules with unused selections")
+        self.assertEqual(
+            faulty_rules, [], Fore.RED + "There are rules with unused selections"
+        )
 
     # def test_field_name_typo(self):
     #     # add "OriginalFilename" after Aurora switched to SourceFilename
@@ -1219,7 +1599,21 @@ class TestRules(unittest.TestCase):
     #     self.assertEqual(faulty_rules, [], Fore.RED + "There are rules with common typos in field names.")
 
     def test_unknown_value_modifier(self):
-        known_modifiers = ["contains", "startswith", "endswith", "all", "base64offset", "base64", "utf16le", "utf16be", "wide", "utf16", "windash", "re", "cidr"]
+        known_modifiers = [
+            "contains",
+            "startswith",
+            "endswith",
+            "all",
+            "base64offset",
+            "base64",
+            "utf16le",
+            "utf16be",
+            "wide",
+            "utf16",
+            "windash",
+            "re",
+            "cidr",
+        ]
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
             detection = self.get_rule_part(file_path=file, part_name="detection")
@@ -1228,34 +1622,54 @@ class TestRules(unittest.TestCase):
                     if isinstance(detection[search_identifier], dict):
                         for field in detection[search_identifier]:
                             if "|" in field:
-                                for current_modifier in field.split('|')[1:]:
+                                for current_modifier in field.split("|")[1:]:
                                     found = False
                                     for target_modifier in known_modifiers:
                                         if current_modifier == target_modifier:
                                             found = True
                                     if not found:
-                                        print(Fore.RED + "Rule {} uses an unknown field modifier ({}/{})".format(file, search_identifier, field))
+                                        print(
+                                            Fore.RED
+                                            + "Rule {} uses an unknown field modifier ({}/{})".format(
+                                                file, search_identifier, field
+                                            )
+                                        )
                                         faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED + "There are rules with unknown value modifiers. Most often it is just a typo.")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with unknown value modifiers. Most often it is just a typo.",
+        )
 
     def test_all_value_modifier_single_item(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             if detection:
                 for search_identifier in detection:
                     if isinstance(detection[search_identifier], dict):
                         for field in detection[search_identifier]:
-                            if "|all" in field and not isinstance(detection[search_identifier][field], list):
-                                print(Fore.RED + "Rule {} uses the 'all' modifier on a single item in selection ({}/{})".format(
-                                    file, search_identifier, field))
+                            if "|all" in field and not isinstance(
+                                detection[search_identifier][field], list
+                            ):
+                                print(
+                                    Fore.RED
+                                    + "Rule {} uses the 'all' modifier on a single item in selection ({}/{})".format(
+                                        file, search_identifier, field
+                                    )
+                                )
                                 faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED + "There are rules with |all modifier only having one item. " +
-                         "Single item values are not allowed to have an all modifier as some back-ends cannot support it. " +
-                         "If you use it as a workaround to duplicate a field in a selection, use a new selection instead.")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules with |all modifier only having one item. "
+            + "Single item values are not allowed to have an all modifier as some back-ends cannot support it. "
+            + "If you use it as a workaround to duplicate a field in a selection, use a new selection instead.",
+        )
 
     def test_field_user_localization(self):
         def checkUser(faulty_rules, dict):
@@ -1268,8 +1682,7 @@ class TestRules(unittest.TestCase):
 
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             for sel_key, sel_value in detection.items():
                 if sel_key == "condition" or sel_key == "timeframe":
                     continue
@@ -1284,58 +1697,78 @@ class TestRules(unittest.TestCase):
                     for item in sel_value:
                         checkUser(faulty_rules, item)
 
-        self.assertEqual(faulty_rules, [], Fore.RED + "There are rules that match using localized user accounts. Better employ a generic version such as:\n" +
-                         "User|contains: # covers many language settings\n" +
-                         "    - 'AUTHORI'\n" +
-                         "    - 'AUTORI'")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED
+            + "There are rules that match using localized user accounts. Better employ a generic version such as:\n"
+            + "User|contains: # covers many language settings\n"
+            + "    - 'AUTHORI'\n"
+            + "    - 'AUTORI'",
+        )
 
     def test_condition_operator_casesensitive(self):
         faulty_rules = []
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             if detection:
                 valid = True
                 if isinstance(detection["condition"], str):
-                    param = detection["condition"].split(' ')
+                    param = detection["condition"].split(" ")
                     for item in param:
-                        if item.lower() == 'or' and not item == 'or':
+                        if item.lower() == "or" and not item == "or":
                             valid = False
-                        elif item.lower() == 'and' and not item == 'and':
+                        elif item.lower() == "and" and not item == "and":
                             valid = False
-                        elif item.lower() == 'not' and not item == 'not':
+                        elif item.lower() == "not" and not item == "not":
                             valid = False
-                        elif item.lower() == 'of' and not item == 'of':
+                        elif item.lower() == "of" and not item == "of":
                             valid = False
                     if not valid:
-                        print(Fore.RED + "Rule {} has a invalid condition '{}' : 'or','and','not','of' are lowercase".format(
-                            file, detection["condition"]))
+                        print(
+                            Fore.RED
+                            + "Rule {} has a invalid condition '{}' : 'or','and','not','of' are lowercase".format(
+                                file, detection["condition"]
+                            )
+                        )
                         faulty_rules.append(file)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules using condition without lowercase operator")
+        self.assertEqual(
+            faulty_rules,
+            [],
+            Fore.RED + "There are rules using condition without lowercase operator",
+        )
 
     def test_broken_thor_logsource_config(self):
-
         faulty_config = False
 
         # This test check of the "thor.yml" config file has a missing "WinEventLog:" prefix in Windows log sources
         path_to_thor_config = "../tests/thor.yml"
-        path_to_thor_config = os.path.join(os.path.dirname(os.path.realpath(__file__)), path_to_thor_config)
-        thor_logsources = self.get_rule_yaml(path_to_thor_config)[0]['logsources']
+        path_to_thor_config = os.path.join(
+            os.path.dirname(os.path.realpath(__file__)), path_to_thor_config
+        )
+        thor_logsources = self.get_rule_yaml(path_to_thor_config)[0]["logsources"]
 
         for key, value in thor_logsources.items():
             try:
                 if value["product"] == "windows":
-                    sources_list = value['sources']
+                    sources_list = value["sources"]
                     for i in sources_list:
-                        if not i.startswith('WinEventLog:'):
+                        if not i.startswith("WinEventLog:"):
                             faulty_config = True
-                            print(Fore.RED + "/tests/thor.yml config file has a broken source. Windows Eventlog sources must start with the keyword 'WinEventLog:'")
+                            print(
+                                Fore.RED
+                                + "/tests/thor.yml config file has a broken source. Windows Eventlog sources must start with the keyword 'WinEventLog:'"
+                            )
             except:
                 pass
 
-        self.assertEqual(faulty_config, False, Fore.RED + "thor.yml configuration file located in 'tests/thor.yml' has a borken log source definition")
+        self.assertEqual(
+            faulty_config,
+            False,
+            Fore.RED
+            + "thor.yml configuration file located in 'tests/thor.yml' has a borken log source definition",
+        )
 
     def test_re_invalid_escapes(self):
         faulty_rules = []
@@ -1353,22 +1786,45 @@ class TestRules(unittest.TestCase):
             l = tuple(re.escape(string.punctuation))
             for c in l:
                 if c == "\\":
-                    allowed_2_be_escaped.append(l[index+1])
+                    allowed_2_be_escaped.append(l[index + 1])
                 index += 1
 
             re_specials = [
-                "A", "b", "B", "d", "D", "f", "n", "r", "s",
-                "S", "t", "v", "w", "W", "Z",
+                "A",
+                "b",
+                "B",
+                "d",
+                "D",
+                "f",
+                "n",
+                "r",
+                "s",
+                "S",
+                "t",
+                "v",
+                "w",
+                "W",
+                "Z",
                 # Match Groups
-                "0", "1", "2", "3", "4", "5",
-                "6", "7", "8", "9",
+                "0",
+                "1",
+                "2",
+                "3",
+                "4",
+                "5",
+                "6",
+                "7",
+                "8",
+                "9",
             ]
             allowed_2_be_escaped.extend(re_specials)
 
-            allowed_2_be_escaped.extend([
-                '"',
-                '\'',
-            ])
+            allowed_2_be_escaped.extend(
+                [
+                    '"',
+                    "'",
+                ]
+            )
 
             return allowed_2_be_escaped
 
@@ -1382,7 +1838,9 @@ class TestRules(unittest.TestCase):
                 # check_item_for_bad_escapes(item)
             elif type(item) == dict and depth <= MAX_DEPTH:
                 for keys, sub_item in item.items():
-                    if "|re" in keys: # Covers both "base64" and "base64offset" modifiers
+                    if (
+                        "|re" in keys
+                    ):  # Covers both "base64" and "base64offset" modifiers
                         if type(sub_item) == str or type(sub_item) == list:
                             check_item_for_bad_escapes(sub_item)
                         else:
@@ -1407,14 +1865,23 @@ class TestRules(unittest.TestCase):
                     if c == "\\":
                         # 'l[index-1] != "\\"' ---> Allows "\\\\"
                         # Check if character after \ is not in escape_allow_list and also not already found
-                        if l[index-1] != "\\" and l[index+1] not in escape_allow_list and l[index+1] not in found_bad_escapes:
+                        if (
+                            l[index - 1] != "\\"
+                            and l[index + 1] not in escape_allow_list
+                            and l[index + 1] not in found_bad_escapes
+                        ):
                             # Only for debugging:
                             # print(f"Illegal escape found {c}{l[index+1]}")
                             found_bad_escapes.append(f"{l[index+1]}")
                     index += 1
 
             if len(found_bad_escapes) > 0:
-                print(Fore.RED + "Rule {} has forbidden escapes in |re '{}'".format(file, ",".join(found_bad_escapes)))
+                print(
+                    Fore.RED
+                    + "Rule {} has forbidden escapes in |re '{}'".format(
+                        file, ",".join(found_bad_escapes)
+                    )
+                )
                 faulty_rules.append(file)
 
         # Create escape_allow_list for this test
@@ -1422,13 +1889,14 @@ class TestRules(unittest.TestCase):
 
         # For each rule file, extract detection and dive into recursion
         for file in self.yield_next_rule_file_path(self.path_to_rules):
-            detection = self.get_rule_part(
-                file_path=file, part_name="detection")
+            detection = self.get_rule_part(file_path=file, part_name="detection")
             if detection:
                 check_list_or_recurse_on_dict(detection, 1, False)
 
-        self.assertEqual(faulty_rules, [], Fore.RED +
-                         "There are rules using illegal re-escapes")
+        self.assertEqual(
+            faulty_rules, [], Fore.RED + "There are rules using illegal re-escapes"
+        )
+
 
 def get_mitre_data():
     """
@@ -1449,38 +1917,54 @@ def get_mitre_data():
     enterprise_techniques = lift.get_enterprise_techniques()
     for t in enterprise_techniques:
         MITRE_TECHNIQUE_NAMES.append(
-            t['name'].lower().replace(' ', '_').replace('-', '_'))
+            t["name"].lower().replace(" ", "_").replace("-", "_")
+        )
         for r in t.external_references:
-            if 'external_id' in r:
-                MITRE_TECHNIQUES.append(r['external_id'].lower())
-        if 'kill_chain_phases' in t:
-            for kc in t['kill_chain_phases']:
-                if 'phase_name' in kc:
-                    MITRE_PHASE_NAMES.add(kc['phase_name'].replace('-', '_'))
+            if "external_id" in r:
+                MITRE_TECHNIQUES.append(r["external_id"].lower())
+        if "kill_chain_phases" in t:
+            for kc in t["kill_chain_phases"]:
+                if "phase_name" in kc:
+                    MITRE_PHASE_NAMES.add(kc["phase_name"].replace("-", "_"))
     # Tools / Malware
     enterprise_tools = lift.get_enterprise_tools()
     for t in enterprise_tools:
         for r in t.external_references:
-            if 'external_id' in r:
-                MITRE_TOOLS.append(r['external_id'].lower())
+            if "external_id" in r:
+                MITRE_TOOLS.append(r["external_id"].lower())
     enterprise_malware = lift.get_enterprise_malware()
     for m in enterprise_malware:
         for r in m.external_references:
-            if 'external_id' in r:
-                MITRE_TOOLS.append(r['external_id'].lower())
+            if "external_id" in r:
+                MITRE_TOOLS.append(r["external_id"].lower())
     # Groups
     enterprise_groups = lift.get_enterprise_groups()
     for g in enterprise_groups:
         for r in g.external_references:
-            if 'external_id' in r:
-                MITRE_GROUPS.append(r['external_id'].lower())
+            if "external_id" in r:
+                MITRE_GROUPS.append(r["external_id"].lower())
 
     # Debugging
-    print("MITRE ATT&CK LIST LENGTHS: %d %d %d %d %d" % (len(MITRE_TECHNIQUES), len(
-        MITRE_TECHNIQUE_NAMES), len(list(MITRE_PHASE_NAMES)), len(MITRE_GROUPS), len(MITRE_TOOLS)))
+    print(
+        "MITRE ATT&CK LIST LENGTHS: %d %d %d %d %d"
+        % (
+            len(MITRE_TECHNIQUES),
+            len(MITRE_TECHNIQUE_NAMES),
+            len(list(MITRE_PHASE_NAMES)),
+            len(MITRE_GROUPS),
+            len(MITRE_TOOLS),
+        )
+    )
 
     # Combine all IDs to a big tag list
-    return ["attack." + item for item in MITRE_TECHNIQUES + MITRE_TECHNIQUE_NAMES + list(MITRE_PHASE_NAMES) + MITRE_GROUPS + MITRE_TOOLS]
+    return [
+        "attack." + item
+        for item in MITRE_TECHNIQUES
+        + MITRE_TECHNIQUE_NAMES
+        + list(MITRE_PHASE_NAMES)
+        + MITRE_GROUPS
+        + MITRE_TOOLS
+    ]
 
 
 if __name__ == "__main__":
